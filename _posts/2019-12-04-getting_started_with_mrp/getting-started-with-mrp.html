<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Getting started with MRP</title>
  
  <meta property="description" itemprop="description" content="Multi-level regression with post-stratification (MRP) is a popular way to adjust non-representative samples to better analyse opinion and other survey responses. I recently ran a hands-on workshop at the ANU, aimed at interested, but not experienced, social scientists to help de-mystify MRP. The workshop aimed to give participants the ability and confidence to: 1) critically read papers that use it; and 2) apply it in their own work. Examples of how to implement MRP were illustrated in R using the brms package. The following post gives the outline of the workshop and the material and coding exercises covered."/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2019-12-03"/>
  <meta property="article:created" itemprop="dateCreated" content="2019-12-03"/>
  <meta name="article:author" content="Rohan Alexander"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Getting started with MRP"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Multi-level regression with post-stratification (MRP) is a popular way to adjust non-representative samples to better analyse opinion and other survey responses. I recently ran a hands-on workshop at the ANU, aimed at interested, but not experienced, social scientists to help de-mystify MRP. The workshop aimed to give participants the ability and confidence to: 1) critically read papers that use it; and 2) apply it in their own work. Examples of how to implement MRP were illustrated in R using the brms package. The following post gives the outline of the workshop and the material and coding exercises covered."/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Getting started with MRP"/>
  <meta property="twitter:description" content="Multi-level regression with post-stratification (MRP) is a popular way to adjust non-representative samples to better analyse opinion and other survey responses. I recently ran a hands-on workshop at the ANU, aimed at interested, but not experienced, social scientists to help de-mystify MRP. The workshop aimed to give participants the ability and confidence to: 1) critically read papers that use it; and 2) apply it in their own work. Examples of how to implement MRP were illustrated in R using the brms package. The following post gives the outline of the workshop and the material and coding exercises covered."/>
  
  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output"]}},"value":[{"type":"character","attributes":{},"value":["Getting started with MRP"]},{"type":"character","attributes":{},"value":["Multi-level regression with post-stratification (MRP) is a popular way to adjust non-representative samples to better analyse opinion and other survey responses. I recently ran a hands-on workshop at the ANU, aimed at interested, but not experienced, social scientists to help de-mystify MRP. The workshop aimed to give participants the ability and confidence to: 1) critically read papers that use it; and 2) apply it in their own work. Examples of how to implement MRP were illustrated in R using the brms package. The following post gives the outline of the workshop and the material and coding exercises covered.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name"]}},"value":[{"type":"character","attributes":{},"value":["Rohan Alexander"]}]}]},{"type":"character","attributes":{},"value":["2019-12-03"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","toc_depth"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]},{"type":"integer","attributes":{},"value":[2]}]}]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["getting-started-with-mrp_files/figure-html5/unnamed-chunk-1-1.png","getting-started-with-mrp_files/figure-html5/unnamed-chunk-2-1.png","inputs/data/number_to_name_divisions 2.csv","inputs/data/number_to_name_divisions.csv","inputs/data/table-female 2.csv","inputs/data/table-female.csv","inputs/data/table-male 2.csv","inputs/data/table-male.csv","inputs/figures/census_cols 2.png","inputs/figures/census_cols.png","inputs/figures/census_download 2.png","inputs/figures/census_download.png","inputs/figures/census_rows.png","inputs/figures/census_select_type 2.png","inputs/figures/census_select_type.png","inputs/figures/census_type.png","inputs/figures/demographics 2.png","inputs/figures/demographics.png","inputs/figures/electoral_college 2.png","inputs/figures/electoral_college.png","inputs/figures/github.png","inputs/figures/states 2.png","inputs/figures/states.png","inputs/figures/tablebuilder.png","inputs/literature/forecasting-with-nonrepresentative-polls 2.pdf","inputs/literature/forecasting-with-nonrepresentative-polls.pdf","outputs/data/census_data 2.csv","outputs/data/census_data.csv","outputs/data/example_poll 2.csv","outputs/data/example_poll.csv","outputs/model/brms_model 2.rds","outputs/model/brms_model_states 2.rds","outputs/model/brms_model_states.rds","outputs/model/brms_model.rds","scripts/make_abs_data 2.R","scripts/make_abs_data.R","scripts/make_poll_data 2.R","scripts/make_poll_data.R"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="getting-started-with-mrp_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="getting-started-with-mrp_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="getting-started-with-mrp_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="getting-started-with-mrp_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Getting started with MRP","description":"Multi-level regression with post-stratification (MRP) is a popular way to adjust non-representative samples to better analyse opinion and other survey responses. I recently ran a hands-on workshop at the ANU, aimed at interested, but not experienced, social scientists to help de-mystify MRP. The workshop aimed to give participants the ability and confidence to: 1) critically read papers that use it; and 2) apply it in their own work. Examples of how to implement MRP were illustrated in R using the brms package. The following post gives the outline of the workshop and the material and coding exercises covered.","authors":[{"author":"Rohan Alexander","authorURL":"#","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2019-12-03T00:00:00.000-05:00","citationText":"Alexander, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Getting started with MRP</h1>
<p>Multi-level regression with post-stratification (MRP) is a popular way to adjust non-representative samples to better analyse opinion and other survey responses. I recently ran a hands-on workshop at the ANU, aimed at interested, but not experienced, social scientists to help de-mystify MRP. The workshop aimed to give participants the ability and confidence to: 1) critically read papers that use it; and 2) apply it in their own work. Examples of how to implement MRP were illustrated in R using the brms package. The following post gives the outline of the workshop and the material and coding exercises covered.</p>
</div>

<div class="d-byline">
  Rohan Alexander  
  
<br/>2019-12-03
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#schedule">Schedule</a></li>
<li><a href="#help-with-computer-set-up.">Help with computer set-up.</a><ul>
<li><a href="#computing">Computing</a></li>
<li><a href="#getting-help">Getting help</a></li>
</ul></li>
<li><a href="#introduction-motivation-and-example">Introduction, motivation, and example</a></li>
<li><a href="#live-coding-introductory-example">Live-coding introductory example</a></li>
<li><a href="#participants-pair-code-introductory-example">Participants pair-code introductory example</a></li>
<li><a href="#live-coding-extended-example">Live coding extended example</a></li>
<li><a href="#participants-pair-code-extended-example">Participants pair-code extended example</a></li>
<li><a href="#live-coding">Live coding</a><ul>
<li><a href="#adding-layers">Adding layers</a></li>
<li><a href="#gathering-data">Gathering data</a></li>
<li><a href="#communication">Communication</a></li>
</ul></li>
<li><a href="#concluding-remarks">Concluding remarks</a></li>
<li><a href="#next-steps">Next steps</a></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<h1 id="overview">Overview</h1>
<p>Multi-level regression with post-stratification (MRP) is a popular way to adjust non-representative samples to better analyse opinion and other survey responses. It uses a regression model to relate individual-level survey responses to various characteristics and then rebuilds the sample to better match the population. In this way MRP can not only allow a better understanding of responses, but also allow us to analyse data that may otherwise be unusable. However, it can be a challenge to get started with MRP as the terminology may be unfamiliar, and the data requirements can be onerous.</p>
<p>The purpose of this hands-on workshop is to de-mystify MRP and give participants the ability and confidence to: 1) critically read papers that use it; and 2) apply it in their own work. Examples of how to implement MRP will be illustrated in R using the brms package. No experience with R is required but workshop participants should bring a laptop that is: a) connected to the internet; b) has R and R Studio installed, along with the tidyverse and brms packages (if you have a hassle doing this then come early to the workshop and I can help you).</p>
<p>The GitHub repo that you should download is: <a href="https://github.com/RohanAlexander/mrp_workshop" class="uri">https://github.com/RohanAlexander/mrp_workshop</a>.</p>
<h1 id="schedule">Schedule</h1>
<ul>
<li>8:45 - 9:00: (Optional) Help with computer set-up.</li>
<li>9:00 - 9:15: Introduction, motivation, and example.</li>
<li>9:15 - 9:25: Live-coding introductory example.</li>
<li>9:25 - 9:45: Participants pair-code introductory example.</li>
<li>9:45 - 9:55: Live coding extended example.</li>
<li>10:00 - 10:30: Participants pair-code extended example.</li>
<li>10:30 - 10:50: Live example improving the workflow: gathering data from the ABS, improving the model, and communicating results.</li>
<li>10:50 - 11:00: Concluding remarks about strengths, weaknesses, and potential areas of application.</li>
</ul>
<h1 id="help-with-computer-set-up.">Help with computer set-up.</h1>
<p>The primary programming language used for MRP tends to be R, but any similar language would be fine. That said, if you are already comfortable with another open source language, such as Python, then it wouldn’t hurt to learn R as well. You are welcome to use whatever language you are most comfortable with, but it will be easiest for you to be able to draw on other examples if you use R. All of the examples in this workshop are in R.</p>
<h2 id="computing">Computing</h2>
<p>R can be downloaded for free from: <a href="http://cran.utstat.utoronto.ca/" class="uri">http://cran.utstat.utoronto.ca/</a>.</p>
<p>RStudio is an interface that makes using R easier and it can be downloaded for free from: <a href="https://rstudio.com/products/rstudio/download/" class="uri">https://rstudio.com/products/rstudio/download/</a>.</p>
<p>We will use brms later in the tutorial. In order to use this your Mac needs to have Xcode and a bunch of other things installed. To do this go to: <a href="https://github.com/rmacoslib/r-macos-rtools#how-do-i-use-the-installer" class="uri">https://github.com/rmacoslib/r-macos-rtools#how-do-i-use-the-installer</a> and within the ‘assets’ bit of the project’s release page, download ‘macos-rtools-3.1.0.pkg’ and then install that. It’ll take a few minutes because it is downloading and setting up a bunch of things.</p>
<h2 id="getting-help">Getting help</h2>
<p>At some point your code won’t run or will throw an error. This is normal, and it happens to everyone. It happens to me on a daily, sometimes hourly, basis. Getting frustrated is understandable. There are a few steps that are worthwhile taking when this happens:</p>
<ul>
<li>If you are having issues with a particular function then the Help file for that function can be accessed by adding a ? to the front. e.g. ‘?lm’.</li>
<li>If you’re getting an error then try googling it, (I find it can help to include the term ‘R’ and ‘MRP’ or ‘tidyverse’ or the relevant package name).</li>
<li>If your code just isn’t running, then try searching for what you are trying to do, e.g. ‘save PDF of graph in R made using ggplot’. Almost always there are relevant blog posts or Stack Overflow answers that will help.</li>
<li>Try to restart R and R Studio and load everything again.</li>
<li>Try to restart your computer.</li>
</ul>
<p>There are a few small mistakes that I often make and may be worth checking in case you make them too:</p>
<ul>
<li>check the class e.g. class(my_dataset$its_column) to make sure that is what it should be;</li>
<li>when you’re using ggplot make sure you use ‘+’ not ‘%&gt;%’;</li>
<li>check whether you are using ‘.’ when you shouldn’t be, or vice versa.</li>
</ul>
<p>It’s almost always helpful to take a break and come back the next day.</p>
<h1 id="introduction-motivation-and-example">Introduction, motivation, and example</h1>
<p>Multi-level regression with post-stratification (MRP) is a handy approach when dealing with survey data. Essentially, it trains a model based on the survey, and then applies that trained model to another dataset. There are two main, related, advantages:</p>
<ol type="1">
<li>It can allow us to ‘re-weight’ in a way that includes uncertainty front-of-mind and isn’t hamstrung by small samples.</li>
<li>It can allow us to use broad surveys to speak to subsets.</li>
</ol>
<p>From a practical perspective, it tends to be less expensive to collect non-probability samples and so there are benefits of being able to use these types of data. That said, it is not a magic-bullet and the laws of statistics still apply. We will have larger uncertainty around our estimates and they will still be subject to all the usual biases. As <a href="https://twitter.com/jazzystats">Lauren Kennedy</a> points out, ‘MRP has traditionally been used in probability surveys and had potential for non-probability surveys, but we’re not sure of the limitations at the moment.’</p>
<p>One famous example is Wei Wang, David Rothschild, Sharad Goel, and Andrew Gelman, 2014, ‘Forecasting elections with non-representative polls’, <em>International Journal of Forecasting</em>. They used data from the Xbox gaming platform to forecast the 2012 US Presidential Election.</p>
<p>Key facts about the set-up:</p>
<ul>
<li>Data from an opt-in poll which was available on the Xbox gaming platform during the 45 days preceding the 2012 US presidential election.</li>
<li>Each day there were three to five questions, including voter intention: “If the election were held today, who would you vote for?”</li>
<li>Respondents were allowed to answer at most once per day.</li>
<li>First-time respondents were asked to provide information about themselves, including their sex, race, age, education, state, party ID, political ideology, and who they voted for in the 2008 presidential election.</li>
<li>In total, 750,148 interviews were conducted, with 345,858 unique respondents - over 30,000 of whom completed five or more polls</li>
<li>Young men dominate the Xbox population: 18-to-29-year-olds comprise 65 per cent of the Xbox dataset, compared to 19 per cent in the exit poll; and men make up 93 per cent of the Xbox sample but only 47 per cent of the electorate.</li>
</ul>
<p>Given the US electorate, they use a two-stage modelling approach. The details don’t really matter too much, and essentially they model how likely a respondent is to vote for Obama, given various information such as state, education, sex, etc: <span class="math display">\[
Pr\left(Y_i = \mbox{Obama} | Y_i\in\{\mbox{Obama, Romney}\}\right) = \mbox{logit}^{-1}(\alpha_0 + \alpha_1(\mbox{state last vote share}) 
+ \alpha_{j[i]}^{\mbox{state}} + \alpha_{j[i]}^{\mbox{edu}} + \alpha_{j[i]}^{\mbox{sex}}...
)
\]</span> They run this in R using glmer() from lme4.</p>
<p>Having a trained model that considers the effect of these various independent variables on support for the candidates, they now post-stratify, where each of these “cell-level estimates are weighted by the proportion of the electorate in each cell and aggregated to the appropriate level (i.e., state or national).”</p>
<p>This means that they need cross-tabulated population data. In general, the census would have worked, or one of the other large surveys available in the US, but the difficulty is that the variables need to be available on a cross-tab basis. As such, they use exit polls (not an option for Australia in general).</p>
<p>They make state-specific estimates by post-stratifying to the features of each state. <img src="inputs/figures/states.png" alt="State estimates from the Xbox paper." /></p>
<p>Similarly, they can examine demographic-differences. <img src="inputs/figures/demographics.png" alt="Demographic differences from the Xbox paper." /></p>
<p>Finally, they convert their estimates into electoral college estimates. <img src="inputs/figures/electoral_college.png" alt="Electoral College estimates from the Xbox paper." /></p>
<h1 id="live-coding-introductory-example">Live-coding introductory example</h1>
<p>The workflow that we are going to use is:</p>
<ol type="1">
<li>read in the poll;</li>
<li>model the poll;</li>
<li>read in the post-stratification data; and</li>
<li>apply the model to the post-stratification data.</li>
</ol>
<p>First load the packages.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# Uncomment these (by deleting the #) if you need to install the packages
# install.packages(&quot;broom&quot;)
# install.packages(&quot;here&quot;)
# install.packages(&quot;skimr&quot;)
# install.packages(&quot;tidyverse&quot;)

library(broom) # Helps make the regression results tidier
library(here) # Helps make file referencing easier.
library(skimr) # Helps summarise the data
library(tidyverse) # Helps make programming with R easier</code></pre>
</div>
<p>Then load some sample polling data to analyse. I have generated this fictitious data so that we have some idea of what to expect from the model. The dependent variable is supports_ALP, which is a binary variable - either 0 or 1. We’ll just use two independent variables here: gender, which is either Female or Male (as that is what is available from the ABS); and age_group, which is one of four groups: ages 18 to 29, ages 30 to 44, ages 45 to 59, ages 60 plus.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
example_poll &lt;- read_csv(&quot;outputs/data/example_poll.csv&quot;) # Here we read in a 
# CSV file and assign it to a dataset called &#39;example_poll&#39;

head(example_poll) # Displays the first 10 rows</code></pre>
<pre><code>
# A tibble: 6 x 4
  gender age_group  supports_ALP state
  &lt;chr&gt;  &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;
1 Male   ages30to44            0 NSW  
2 Female ages45to59            0 NSW  
3 Female ages60plus            1 VIC  
4 Male   ages30to44            1 QLD  
5 Female ages30to44            1 QLD  
6 Female ages18to29            1 VIC  </code></pre>
<pre class="r"><code>
# Look at some summary statistics to make sure the data seem reasonable
summary(example_poll) </code></pre>
<pre><code>
    gender           age_group          supports_ALP   
 Length:5000        Length:5000        Min.   :0.0000  
 Class :character   Class :character   1st Qu.:0.0000  
 Mode  :character   Mode  :character   Median :1.0000  
                                       Mean   :0.5514  
                                       3rd Qu.:1.0000  
                                       Max.   :1.0000  
    state          
 Length:5000       
 Class :character  
 Mode  :character  
                   
                   
                   </code></pre>
<pre class="r"><code>
skimr::skim(example_poll)</code></pre>
<table>
<caption>(#tab:initial_model_simulate_data)Data summary</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;">Name</td>
<td style="text-align: left;">example_poll</td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of rows</td>
<td style="text-align: left;">5000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Number of columns</td>
<td style="text-align: left;">4</td>
</tr>
<tr class="even">
<td style="text-align: left;">_______________________</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Column type frequency:</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">character</td>
<td style="text-align: left;">3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">________________________</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Group variables</td>
<td style="text-align: left;">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">skim_variable</th>
<th style="text-align: right;">n_missing</th>
<th style="text-align: right;">complete_rate</th>
<th style="text-align: right;">min</th>
<th style="text-align: right;">max</th>
<th style="text-align: right;">empty</th>
<th style="text-align: right;">n_unique</th>
<th style="text-align: right;">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">gender</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">age_group</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">state</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">skim_variable</th>
<th style="text-align: right;">n_missing</th>
<th style="text-align: right;">complete_rate</th>
<th style="text-align: right;">mean</th>
<th style="text-align: right;">sd</th>
<th style="text-align: right;">p0</th>
<th style="text-align: right;">p25</th>
<th style="text-align: right;">p50</th>
<th style="text-align: right;">p75</th>
<th style="text-align: right;">p100</th>
<th style="text-align: left;">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">supports_ALP</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.55</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: left;">▆▁▁▁▇</td>
</tr>
</tbody>
</table>
</div>
<p>I generated this polling data to make both made males and older people less likely to vote for the Australian Labor Party; and females and younger people more likely to vote for the Labor Party. Females are over-sampled. As such, we should have an ALP skew on the dataset.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# The &#39;%&gt;%&#39; is called a &#39;pipe&#39; and it takes whatever the output is of the 
# command before it, and pipes it to the command after it.
example_poll %&gt;% # So we are taking our example_poll dataset and using it as an 
  # input to &#39;summarise&#39;.
   # summarise reduces the dimensions, so here we will get one number from a column.
  summarise(raw_ALP_prop = sum(supports_ALP) / nrow(example_poll))</code></pre>
<pre><code>
# A tibble: 1 x 1
  raw_ALP_prop
         &lt;dbl&gt;
1        0.551</code></pre>
</div>
<p>Now we’d like to see if we can get our results back (we should find females less likely than males to vote for Australian Labor Party and that people are less likely to vote Australian Labor Party as they get older). Our model is: <span class="math display">\[
\mbox{ALP support}_j = \mbox{gender}_j + \mbox{age_group}_j + \epsilon_j.
\]</span></p>
<p>This model says that the probability that some person, <span class="math inline">\(j\)</span>, will vote for the Australian Labor Party depends on their gender and their age-group. Based on our simulated data, we would like older age-groups to be less likely to vote for the Australian Labor Party and for males to be less likely to vote for the Australian Labor Party.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# Here we are running an OLS regression with supports_ALP as the dependent variable 
# and gender and age_group as the independent variables. The dataset that we are 
# using is example_poll. We are then saving that OLS regression to a variable called &#39;model&#39;.
model &lt;- lm(supports_ALP ~ gender + age_group, 
            data = example_poll
            )

# broom::tidy just displays the outputs of the regression in a nice table.
broom::tidy(model) </code></pre>
<pre><code>
# A tibble: 5 x 5
  term                estimate std.error statistic   p.value
  &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept)            0.900    0.0131      68.8 0.       
2 genderMale            -0.205    0.0142     -14.4 2.69e- 46
3 age_groupages30to44   -0.186    0.0176     -10.6 6.50e- 26
4 age_groupages45to59   -0.402    0.0177     -22.7 8.29e-109
5 age_groupages60plus   -0.585    0.0175     -33.4 5.20e-221</code></pre>
</div>
<p>Essentially we’ve got our inputs back. We just used regular OLS even though our dependent variable is a binary. (It’s usually fine to start with an OLS model and then iterate toward an approach that may be more appropriate such as logistic regression or whatever, but where the results are a little more difficult to interpret.) If you wanted to do that then the place to start would be glmer() from the R package lme4, and we’ll see that in the next section.</p>
<aside>
<a href="https://www.monicaalexander.com/">Monica</a> is horrified by the use of OLS here, and wants it on the record that she regrets not making not doing this part of our marriage vows.
</aside>
<p>Now we’d like to see if we can use what we found in the poll to get an estimate for each state based on their demographic features.</p>
<p>First read in some real demographic data, on a seat basis, from the ABS (we’ll go into the process of getting this later).</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
census_data &lt;- read_csv(&quot;outputs/data/census_data.csv&quot;)
head(census_data)</code></pre>
<pre><code>
# A tibble: 6 x 5
  state gender age_group  number cell_prop_of_division_total
  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;                       &lt;dbl&gt;
1 ACT   Female ages18to29  34683                       0.125
2 ACT   Female ages30to44  42980                       0.155
3 ACT   Female ages45to59  33769                       0.122
4 ACT   Female ages60plus  30322                       0.109
5 ACT   Male   ages18to29  34163                       0.123
6 ACT   Male   ages30to44  41288                       0.149</code></pre>
</div>
<p>We’re just going to do some rough forecasts. For each gender and age_group we want the relevant coefficient in the example_data and we can construct the estimates.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# Here we are making predictions using our model with some new data from the 
# census, and we saving the results of those predictions by adding a new column 
# to the census_data dataset called &#39;estimate&#39;.
census_data$estimate &lt;- 
  model %&gt;% 
  predict(newdata = census_data)

census_data %&gt;% 
  mutate(alp_predict_prop = estimate*cell_prop_of_division_total) %&gt;% 
  group_by(state) %&gt;% 
  summarise(alp_predict = sum(alp_predict_prop))</code></pre>
<pre><code>
# A tibble: 8 x 2
  state alp_predict
  &lt;chr&gt;       &lt;dbl&gt;
1 ACT         0.525
2 NSW         0.495
3 NT          0.541
4 QLD         0.496
5 SA          0.479
6 TAS         0.464
7 VIC         0.503
8 WA          0.503</code></pre>
</div>
<p>We now have post-stratified estimates for each division. Our model has a fair few weaknesses. For instance small cell counts are going to be problematic. And our approach ignores uncertainty, but now that we have something working we can complicate it.</p>
<h1 id="participants-pair-code-introductory-example">Participants pair-code introductory example</h1>
<p><em>Please break into pairs and with one person ‘driving’ (typing) and the other person ‘navigating’, and attempt to pair-code the introductory example.</em></p>
<p>If you run into issues then I am happy to help point you in the right direction. The full code of the example will be made available after the workshop, so it doesn’t matter if you’re not able to complete the example now.</p>
<p>As a reminder, our workflow is:</p>
<ol type="1">
<li>read in the poll;</li>
<li>model the poll;</li>
<li>read in the post-stratification data;</li>
<li>apply your model to the post-stratification data.</li>
</ol>
<p>Get started by opening the Rproj file from the workshop repo and opening a new R script.</p>
<h1 id="live-coding-extended-example">Live coding extended example</h1>
<p>We’d like to address some of the major issues with our approach, specifically being able to deal with small cell counts, and also taking better account of uncertainty. As we are dealing with survey data, prediction intervals or something similar are crticial, and it’s not appropriate to only report central estimates. To do this we’ll use the same broad approach as before, but just improving bits of our workflow.</p>
<p>First load the packages.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# Uncomment these if you need to install the packages
# install.packages(&quot;broom&quot;)
# install.packages(&quot;brms&quot;)
# install.packages(&quot;here&quot;) 
# install.packages(&quot;tidybayes&quot;)
# install.packages(&quot;tidyverse&quot;) 

library(broom)
library(brms) # Used for the modelling
library(here)
library(tidybayes) # Used to help understand the modelling estimates
library(tidyverse) </code></pre>
</div>
<p>As before, read in the polling dataset.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
example_poll &lt;- read_csv(&quot;outputs/data/example_poll.csv&quot;)

head(example_poll)</code></pre>
<pre><code>
# A tibble: 6 x 4
  gender age_group  supports_ALP state
  &lt;chr&gt;  &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;
1 Male   ages30to44            0 NSW  
2 Female ages45to59            0 NSW  
3 Female ages60plus            1 VIC  
4 Male   ages30to44            1 QLD  
5 Female ages30to44            1 QLD  
6 Female ages18to29            1 VIC  </code></pre>
</div>
<p>Now, using the same basic model as before, but we move it to a setting that acknowledges the dependent variable as being binary, and in a Bayesian setting.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
model &lt;- brm(supports_ALP ~ gender + age_group, 
             data = example_poll, 
             family = bernoulli(),
             file = &quot;outputs/model/brms_model&quot;
             )

model &lt;- read_rds(&quot;outputs/model/brms_model.rds&quot;)

summary(model)</code></pre>
<pre><code>
 Family: bernoulli 
  Links: mu = logit 
Formula: supports_ALP ~ gender + age_group 
   Data: example_poll (Number of observations: 5000) 
Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 4000

Population-Level Effects: 
                    Estimate Est.Error l-95% CI u-95% CI Rhat
Intercept               2.07      0.09     1.91     2.23 1.00
genderMale             -1.06      0.07    -1.20    -0.91 1.00
age_groupages30to44    -1.10      0.10    -1.29    -0.91 1.00
age_groupages45to59    -2.04      0.10    -2.23    -1.85 1.00
age_groupages60plus    -2.88      0.10    -3.09    -2.68 1.00
                    Bulk_ESS Tail_ESS
Intercept               2240     2194
genderMale              3403     2595
age_groupages30to44     2483     2805
age_groupages45to59     2521     3061
age_groupages60plus     2517     2858

Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<p>We’ve moved to the Bernoulli distribution, so we have to do a bit more work to understand our results, but we are broadly getting back what we’d expect.</p>
<p>As before, we’d like an estimate for each state based on their demographic features and start by reading in the data.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
census_data &lt;- read_csv(&quot;outputs/data/census_data.csv&quot;)
head(census_data)</code></pre>
<pre><code>
# A tibble: 6 x 5
  state gender age_group  number cell_prop_of_division_total
  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;                       &lt;dbl&gt;
1 ACT   Female ages18to29  34683                       0.125
2 ACT   Female ages30to44  42980                       0.155
3 ACT   Female ages45to59  33769                       0.122
4 ACT   Female ages60plus  30322                       0.109
5 ACT   Male   ages18to29  34163                       0.123
6 ACT   Male   ages30to44  41288                       0.149</code></pre>
</div>
<p>We’re just going to do some rough forecasts. For each gender and age_group we want the relevant coefficient in the example_data and we can construct the estimates (this code is from Monica Alexander, <a href="https://www.monicaalexander.com/posts/2019-08-07-mrp/" class="uri">https://www.monicaalexander.com/posts/2019-08-07-mrp/</a>).</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
post_stratified_estimates &lt;- 
  model %&gt;% 
  tidybayes::add_predicted_draws(newdata = census_data) %&gt;% 
  rename(alp_predict = .prediction) %&gt;% 
  mutate(alp_predict_prop = alp_predict*cell_prop_of_division_total) %&gt;% 
  group_by(state, .draw) %&gt;% 
  summarise(alp_predict = sum(alp_predict_prop)) %&gt;% 
  group_by(state) %&gt;% 
  summarise(mean = mean(alp_predict), 
            lower = quantile(alp_predict, 0.025), 
            upper = quantile(alp_predict, 0.975))

post_stratified_estimates</code></pre>
<pre><code>
# A tibble: 8 x 4
  state  mean lower upper
  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 ACT   0.526 0.243 0.791
2 NSW   0.491 0.214 0.750
3 NT    0.538 0.236 0.852
4 QLD   0.493 0.215 0.762
5 SA    0.478 0.201 0.761
6 TAS   0.460 0.183 0.757
7 VIC   0.501 0.224 0.766
8 WA    0.506 0.219 0.769</code></pre>
</div>
<p>We now have post-stratified estimates for each division. Our new Bayesian approach will enable us to think more deeply about uncertainty. We could complicate this in a variety of ways including adding more coefficients (but remember that we’d need to get new cell counts), or adding some layers.</p>
<h1 id="participants-pair-code-extended-example">Participants pair-code extended example</h1>
<p><em>Please break into the same pairs as before, but swap who is typing, and attempt to pair-code the extended example.</em></p>
<p>If you run into issues then I am happy to help point you in the right direction. The full code of the example will be made available after the workshop, so it doesn’t matter if you’re not able to complete the example now.</p>
<p>As a reminder, our workflow is:</p>
<ol type="1">
<li>read in the poll;</li>
<li>model the poll;</li>
<li>read in the post-stratification data;</li>
<li>apply your model to the post-stratification data.</li>
</ol>
<h1 id="live-coding">Live coding</h1>
<p>I will now briefly demonstrate some other aspects that may be useful to improve three aspects of our MRP workflow:</p>
<ol type="1">
<li>(Workflow step 2) adding some more complexity to our model; and</li>
<li>(Workflow step 3) gathering and preparing some data from the ABS that we could use to post-stratify on.</li>
</ol>
<p>We will also add a fifth stage to our workflow: Communicating our results.</p>
<h2 id="adding-layers">Adding layers</h2>
<p>We may like to try to add some layers to our model. For instance, we may like a different intercept for each state.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
model_states &lt;- brm(supports_ALP ~ gender + age_group + (1|state), 
                    data = example_poll, 
                    family = bernoulli(),
                    file = &quot;outputs/model/brms_model_states&quot;,
                    control = list(adapt_delta = 0.90)
                    )
summary(model_states)</code></pre>
<pre><code>
 Family: bernoulli 
  Links: mu = logit 
Formula: supports_ALP ~ gender + age_group + (1 | state) 
   Data: example_poll (Number of observations: 5000) 
Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 4000

Group-Level Effects: 
~state (Number of levels: 8) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
sd(Intercept)     0.06      0.05     0.00     0.20 1.00     1553
              Tail_ESS
sd(Intercept)     2072

Population-Level Effects: 
                    Estimate Est.Error l-95% CI u-95% CI Rhat
Intercept               2.07      0.09     1.90     2.26 1.00
genderMale             -1.06      0.08    -1.21    -0.91 1.00
age_groupages30to44    -1.10      0.10    -1.30    -0.90 1.00
age_groupages45to59    -2.04      0.10    -2.24    -1.84 1.00
age_groupages60plus    -2.89      0.10    -3.10    -2.69 1.00
                    Bulk_ESS Tail_ESS
Intercept               1660     2273
genderMale              4106     2833
age_groupages30to44     2110     2566
age_groupages45to59     2058     2347
age_groupages60plus     2201     2581

Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>
broom::tidy(model_states, par_type = &quot;varying&quot;)</code></pre>
<pre><code>
       term group level      estimate  std.error       lower
1 Intercept state   ACT -0.0168699419 0.07074301 -0.14969628
2 Intercept state   NSW  0.0017210052 0.04612268 -0.07223933
3 Intercept state    NT  0.0153301257 0.07586938 -0.08509056
4 Intercept state   QLD  0.0249702604 0.05321612 -0.04216737
5 Intercept state    SA  0.0150266070 0.05864962 -0.06881398
6 Intercept state   TAS -0.0146658602 0.07317706 -0.14542943
7 Intercept state   VIC -0.0263030593 0.05188695 -0.12296610
8 Intercept state    WA -0.0006364996 0.05548879 -0.09364575
       upper
1 0.07652361
2 0.07734117
3 0.14549805
4 0.12297713
5 0.12224758
6 0.08379179
7 0.04212995
8 0.08755071</code></pre>
<pre class="r"><code>
broom::tidy(model_states, par_type = &quot;non-varying&quot;, robust = TRUE)</code></pre>
<pre><code>
                 term  estimate  std.error     lower      upper
1           Intercept  2.069011 0.08988424  1.919983  2.2237171
2          genderMale -1.058954 0.07408394 -1.186584 -0.9351159
3 age_groupages30to44 -1.097002 0.10370072 -1.264609 -0.9257060
4 age_groupages45to59 -2.038541 0.10100761 -2.205630 -1.8753367
5 age_groupages60plus -2.884174 0.10356840 -3.063525 -2.7166738</code></pre>
</div>
<p>One interesting aspect is that our multi-level approach will allow us to deal with small cell counts by borrowing information from other cells.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
example_poll %&gt;% 
  count(state)</code></pre>
<pre><code>
# A tibble: 8 x 2
  state     n
  &lt;chr&gt; &lt;int&gt;
1 ACT     107
2 NSW    1622
3 NT       50
4 QLD     982
5 SA      359
6 TAS     105
7 VIC    1285
8 WA      490</code></pre>
</div>
<p>At the moment we have 50 respondents in the Northern Territory, 105 in Tasmania, and 107 in the ACT. Even if we were to remove most of the, say, 18 to 29 year old, male respondents from Tasmania our model would still provide estimates. It does this by pooling, in which the effect of these young, male, Tasmanians is partially determined by other cells that do have respondents.</p>
<h2 id="gathering-data">Gathering data</h2>
<p>Getting data tends to be the most troublesome aspect. I’ve found that the census is fairly useful although it can require some trade-offs (e.g. if you are doing political work then it’s not exactly the same as the electoral roll even if you restrict it to Australian citizens aged at least 18). Nonetheless, I’ve found the best way to get the sub-cell counts is to use ABS TableBuilder. There are two versions - ‘basic’ which is free, and ‘pro’, which is normally $2,510 per year, but which you can get access to if you’re associated with an Australian university.</p>
<figure>
<img src="inputs/figures/tablebuilder.png" alt="TableBuilder front page." /><figcaption>TableBuilder front page.</figcaption>
</figure>
<p>Once you create an account then you can access census data for 2006, 2011, and 2016. (The ABS have relatively recently done some linking between censuses so there is actually some linked data, which is exciting).</p>
<figure>
<img src="inputs/figures/census_select_type.png" alt="TableBuilder after logging in." /><figcaption>TableBuilder after logging in.</figcaption>
</figure>
<p>The website is a bit cumbersome, but considering what they provide it is worth sticking with it. I usually use ‘Counting Persons, Place of Usual Residence’, but sometimes ‘Counting Persons, Place of Enumeration’ is also handy.</p>
<figure>
<img src="inputs/figures/census_type.png" alt="TableBuilder selecting which census." /><figcaption>TableBuilder selecting which census.</figcaption>
</figure>
<p>We want to create a new table, and we do this by specifying the columns and rows.</p>
<figure>
<img src="inputs/figures/census_cols.png" alt="TableBuilder selecting columns." /><figcaption>TableBuilder selecting columns.</figcaption>
</figure>
<p>Once you have the set-up that you want then you can retrieve the data.</p>
<figure>
<img src="inputs/figures/census_rows.png" alt="TableBuilder selecting rows." /><figcaption>TableBuilder selecting rows.</figcaption>
</figure>
<p>You can download the data in various Excel, CSV, and other formats. If your dataset is large then you may need to submit for it to be built, which can take a day or two. Finally, if your sub-cell counts are especially small, then they will be blown around by the randomness that the ABS adds.</p>
<figure>
<img src="inputs/figures/census_download.png" alt="TableBuilder downloading data and creating custom groups." /><figcaption>TableBuilder downloading data and creating custom groups.</figcaption>
</figure>
<p>Helpfully you can create custom groupings for geography, say to load specific electorates, and other aspects, such as age-groups. To get started with this, select ‘Custom data’.</p>
<h2 id="communication">Communication</h2>
<p>There are many interesting aspects that we may like to communicate to others. For instance, we may like to show how the model is affecting the results. We can make a graph that compares the raw estimate with the model estimate.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
post_stratified_estimates %&gt;% 
  ggplot(aes(y = mean, x = forcats::fct_inorder(state), color = &quot;MRP estimate&quot;)) + 
  geom_point() +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0) + 
  ylab(&quot;Proportion ALP support&quot;) + 
  xlab(&quot;State&quot;) + 
  geom_point(data = example_poll %&gt;% 
               group_by(state, supports_ALP) %&gt;%
               summarise(n = n()) %&gt;% 
               group_by(state) %&gt;% 
               mutate(prop = n/sum(n)) %&gt;% 
               filter(supports_ALP==1), 
             aes(state, prop, color = &quot;Raw data&quot;)) +
  theme_minimal() +
  scale_color_brewer(palette = &quot;Set1&quot;) +
  theme(legend.position = &quot;bottom&quot;) +
  theme(legend.title = element_blank())</code></pre>
<p><img src="getting-started-with-mrp_files/figure-html5/unnamed-chunk-1-1.png" width="624" /></p>
</div>
<p>Similarly, we may like to plot the distribution of the coefficients.</p>
<aside>
You can work out which coefficients to be pass to gather_draws by using tidybayes::get_variables(model). (In this example I passed ‘b_.’, but the ones of interest to you may be different.)
</aside>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
model %&gt;%
  gather_draws(`b_.*`, regex=TRUE) %&gt;%
  ungroup() %&gt;%
  mutate(coefficient = stringr::str_replace_all(.variable, c(&quot;b_&quot; = &quot;&quot;))) %&gt;%
  mutate(coefficient = forcats::fct_recode(coefficient,
                                           Intercept = &quot;Intercept&quot;,
                                           `Is male` = &quot;genderMale&quot;,
                                           `Age 30-44` = &quot;age_groupages30to44&quot;,
                                           `Age 45-59` = &quot;age_groupages45to59&quot;,
                                           `Age 60+` = &quot;age_groupages60plus&quot;
                                           )) %&gt;% 

# both %&gt;% 
  ggplot(aes(y=fct_rev(coefficient), x = .value)) + 
  ggridges::geom_density_ridges2(aes(height = ..density..),
                                 rel_min_height = 0.01, 
                                 stat = &quot;density&quot;,
                                 scale=1.5) +
  xlab(&quot;Distribution of estimate&quot;) +
  ylab(&quot;Coefficient&quot;) +
  scale_fill_brewer(name = &quot;Dataset: &quot;, palette = &quot;Set1&quot;) +
  theme_minimal() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  theme(legend.position = &quot;bottom&quot;)</code></pre>
<p><img src="getting-started-with-mrp_files/figure-html5/unnamed-chunk-2-1.png" width="624" /></p>
</div>
<h1 id="concluding-remarks">Concluding remarks</h1>
<p>In general, MRP is a good way to accomplish specific aims, but it’s not without trade-offs. If you have a good quality survey, then it may be a way to speak to disaggregated aspects of it. Or if you are concerned about uncertainty then it is a good way to think about that. If you have a biased survey then it’s a great place to start, but it’s not a panacea.</p>
<p>There’s not a lot of work that’s been done using Australian data, so there’s plenty of scope for exciting work. I look forward to seeing what you do with it!</p>
<h1 id="next-steps">Next steps</h1>
<p>There are a lot of resources out there that would make great next steps. I recommend having a look at the following resources to see which speaks best to your interests and background.</p>
<ol type="1">
<li>Alexander, Monica, 2019, ‘Analyzing name changes after marriage using a non-representative survey’, available at: <a href="https://www.monicaalexander.com/posts/2019-08-07-mrp/" class="uri">https://www.monicaalexander.com/posts/2019-08-07-mrp/</a>.</li>
<li>Kennedy, Lauren, and Jonah Gabry, 2019, ‘MRP with rstanarm’, available at: <a href="https://mc-stan.org/rstanarm/articles/mrp.html" class="uri">https://mc-stan.org/rstanarm/articles/mrp.html</a>.</li>
<li>Kennedy, Lauren, and Andrew Gelman, 2019, ‘Know your population and know your model: Using model-based regression and poststratification to generalize findings beyond the observed sample’, available at: <a href="https://arxiv.org/abs/1906.11323" class="uri">https://arxiv.org/abs/1906.11323</a>.</li>
<li>Kastellec, Jonathan, Jeffrey Lax, and Justin Phillips, 2016, ‘Estimating State Public Opinion With Multi-Level Regression and Poststratification using R’, available at: <a href="https://scholar.princeton.edu/sites/default/files/jkastellec/files/mrp_primer.pdf" class="uri">https://scholar.princeton.edu/sites/default/files/jkastellec/files/mrp_primer.pdf</a>.</li>
<li>Hanretty, Chris, 2019, ‘An introduction to multilevel regression and post-stratification for estimating constituency opinion’, available at: <a href="https://journals.sagepub.com/doi/abs/10.1177/1478929919864773" class="uri">https://journals.sagepub.com/doi/abs/10.1177/1478929919864773</a>.</li>
<li>Downes, Marnie, Lyle Gurrin, Dallas English, Jane Pirkis, Dianne Currier, Matthew Spittal, and John Carlin, 2018, ‘Multilevel Regression and Poststratification: A Modeling Approach to Estimating Population Quantities From Highly Selected Survey Samples’, available at: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29635276" class="uri">https://www.ncbi.nlm.nih.gov/pubmed/29635276</a>.</li>
<li>Jackman, Simon, Shaun Ratcliff, and Luke Mansillo, 2019, ‘Small area estimates of public opinion: Model-assisted post-stratification of data from voter advice applications’, available at: <a href="https://www.cambridge.org/core/membership/services/aop-file-manager/file/5c2f6ebb7cf9ee1118d11c0a/APMM-2019-Simon-Jackman.pdf" class="uri">https://www.cambridge.org/core/membership/services/aop-file-manager/file/5c2f6ebb7cf9ee1118d11c0a/APMM-2019-Simon-Jackman.pdf</a></li>
<li>(Self-promotion alert) Alexander, Rohan, Patrick Dumont, and Patrick Leslie, 2019, ‘Forecasting Multi-District Election’, available at: <a href="https://github.com/RohanAlexander/ForecastingMultiDistrictElections" class="uri">https://github.com/RohanAlexander/ForecastingMultiDistrictElections</a>.</li>
</ol>
<p>If you don’t have survey data, then there is some individual-level data available on the Australian Data Archive: <a href="https://ada.edu.au" class="uri">https://ada.edu.au</a>. You will need to request access to the datasets, but they are very keen for people to use their data and will help you through the process if needed.</p>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
