<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Gathering and analysing text data</title>
  
  <meta property="description" itemprop="description" content="Text modelling is an exciting area of research. But many guides assume that you already have a nice dataset. Similarly, web scraping is an exciting way to get information, but not many explanations go on to explain what you could do with it. This post attempts to go from scraping text from a website through to modelling the topics. It&#39;s not meant to be an exhaustive post, but should hopefully provide enough that you can get started with your own project and know where to go for more information."/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2019-01-03"/>
  <meta property="article:created" itemprop="dateCreated" content="2019-01-03"/>
  <meta name="article:author" content="Rohan Alexander"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Gathering and analysing text data"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Text modelling is an exciting area of research. But many guides assume that you already have a nice dataset. Similarly, web scraping is an exciting way to get information, but not many explanations go on to explain what you could do with it. This post attempts to go from scraping text from a website through to modelling the topics. It&#39;s not meant to be an exhaustive post, but should hopefully provide enough that you can get started with your own project and know where to go for more information."/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Gathering and analysing text data"/>
  <meta property="twitter:description" content="Text modelling is an exciting area of research. But many guides assume that you already have a nice dataset. Similarly, web scraping is an exciting way to get information, but not many explanations go on to explain what you could do with it. This post attempts to go from scraping text from a website through to modelling the topics. It&#39;s not meant to be an exhaustive post, but should hopefully provide enough that you can get started with your own project and know where to go for more information."/>
  
  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output"]}},"value":[{"type":"character","attributes":{},"value":["Gathering and analysing text data"]},{"type":"character","attributes":{},"value":["Text modelling is an exciting area of research. But many guides assume that you already have a nice dataset. Similarly, web scraping is an exciting way to get information, but not many explanations go on to explain what you could do with it. This post attempts to go from scraping text from a website through to modelling the topics. It's not meant to be an exhaustive post, but should hopefully provide enough that you can get started with your own project and know where to go for more information.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name"]}},"value":[{"type":"character","attributes":{},"value":["Rohan Alexander"]}]}]},{"type":"character","attributes":{},"value":["01-03-2019"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["toc","self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[true]},{"type":"logical","attributes":{},"value":[false]}]}]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["addresses.csv","gathering-and-analysing-text-data_files/figure-html5/diagnosticmeasuregraphs-1.png","gathering-and-analysing-text-data_files/figure-html5/exlusitivty-1.png"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="gathering-and-analysing-text-data_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="gathering-and-analysing-text-data_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="gathering-and-analysing-text-data_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="gathering-and-analysing-text-data_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Gathering and analysing text data","description":"Text modelling is an exciting area of research. But many guides assume that you already have a nice dataset. Similarly, web scraping is an exciting way to get information, but not many explanations go on to explain what you could do with it. This post attempts to go from scraping text from a website through to modelling the topics. It's not meant to be an exhaustive post, but should hopefully provide enough that you can get started with your own project and know where to go for more information.","authors":[{"author":"Rohan Alexander","authorURL":"#","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2019-01-03T00:00:00.000-05:00","citationText":"Alexander, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Gathering and analysing text data</h1>
<p>Text modelling is an exciting area of research. But many guides assume that you already have a nice dataset. Similarly, web scraping is an exciting way to get information, but not many explanations go on to explain what you could do with it. This post attempts to go from scraping text from a website through to modelling the topics. It’s not meant to be an exhaustive post, but should hopefully provide enough that you can get started with your own project and know where to go for more information.</p>
</div>

<div class="d-byline">
  Rohan Alexander  
  
<br/>01-03-2019
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#gathering-data">Gathering data</a></li>
<li><a href="#analysing-data">Analysing data</a></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<h1 id="introduction">Introduction</h1>
<p>Text modelling is an exciting area of research. But many guides assume that you already have a nice dataset. Similarly, web scraping is an exciting way to get information, but not many explanations go on to explain what you could do with it. This post attempts to go from scraping text from a website through to modelling the topics. It’s not meant to be an exhaustive post, but should hopefully provide enough that you can get started with your own project and know where to go for more information.</p>
<p>The example that I’m going to use is getting data from the minutes of the RBA board meeting.</p>
<h1 id="gathering-data">Gathering data</h1>
<p>The first step is to get some data. I’m going to use the rvest package to do the web scraping. When you are scraping data you should try to be polite - slow down your requests as much as possible, avoid times you know they’ll have a lot of traffic, and check if the website has an API or a robots.txt file (usually access that at domain.com/robots.txt) that provides guidance.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# install.packages(&quot;rvest&quot;)
library(rvest)
# install.packages(&quot;tidyverse&quot;)
library(tidyverse)

# Read in the list of the website addresses
data_to_scrape &lt;- read_csv(&quot;inputs/addresses.csv&quot;) # Just a list of the URLs 
# and dates for each minutes.
address_to_visit &lt;- data_to_scrape$address
save_name &lt;- data_to_scrape$save_name

# Create the function that will visit address_to_visit and save to save_name files
visit_address_and_save_content &lt;-
  function(name_of_address_to_visit,
           name_of_file_to_save_as) {
    # The function takes two inputs
    read_html(name_of_address_to_visit) %&gt;% # Go to the website and read the html
      html_node(&quot;#content&quot;) %&gt;% # Find the content part
      html_text() %&gt;% # Extract the text of the content part
      write_lines(name_of_file_to_save_as) # Save as a text file
    print(paste(&quot;Done with&quot;, name_of_address_to_visit, &quot;at&quot;, Sys.time()))  
    # Helpful so that you know progress when running it on all the records
    Sys.sleep(sample(30:60, 1)) # Space out each request by somewhere between 
    # 30 and 60 seconds each so that we don&#39;t overwhelm their server
  }

# If there is an error then ignore it and move to the next one
visit_address_and_save_content &lt;-
  safely(visit_address_and_save_content)

# Walk through the addresses and apply the function to each
walk2(address_to_visit,
      save_name,
      ~ visit_address_and_save_content(.x, .y)) </code></pre>
</div>
<p>The CSV with the addresses and save names that we use looks something like this:</p>
<div class="layout-chunk" data-layout="l-body">
<table>
<thead>
<tr class="header">
<th style="text-align: left;">address</th>
<th style="text-align: left;">save_name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a href="https://www.rba.gov.au/monetary-policy/rba-board-minutes/2018/2018-11-06.html" class="uri">https://www.rba.gov.au/monetary-policy/rba-board-minutes/2018/2018-11-06.html</a></td>
<td style="text-align: left;">inputs/minutes/2018-11-06.txt</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a href="https://www.rba.gov.au/monetary-policy/rba-board-minutes/2018/2018-10-02.html" class="uri">https://www.rba.gov.au/monetary-policy/rba-board-minutes/2018/2018-10-02.html</a></td>
<td style="text-align: left;">inputs/minutes/2018-10-02.txt</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a href="https://www.rba.gov.au/monetary-policy/rba-board-minutes/2018/2018-09-04.html" class="uri">https://www.rba.gov.au/monetary-policy/rba-board-minutes/2018/2018-09-04.html</a></td>
<td style="text-align: left;">inputs/minutes/2018-09-04.txt</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a href="https://www.rba.gov.au/monetary-policy/rba-board-minutes/2018/2018-08-07.html" class="uri">https://www.rba.gov.au/monetary-policy/rba-board-minutes/2018/2018-08-07.html</a></td>
<td style="text-align: left;">inputs/minutes/2018-08-07.txt</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a href="https://www.rba.gov.au/monetary-policy/rba-board-minutes/2018/2018-07-03.html" class="uri">https://www.rba.gov.au/monetary-policy/rba-board-minutes/2018/2018-07-03.html</a></td>
<td style="text-align: left;">inputs/minutes/2018-07-03.txt</td>
</tr>
</tbody>
</table>
</div>
<h1 id="analysing-data">Analysing data</h1>
<p>In this example we’ll use a whole bunch of packages so that you can see what’s available. In general probably stringr, quanteda and stm are the workhorse packages with others used as needed.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#### Workspace set-up ####
# install.packages(&quot;broom&quot;)
library(broom) # Used to clean up results
# install.packages(&quot;devtools&quot;)
library(devtools)
# devtools::install_github(&quot;DavisVaughan/furrr&quot;)
library(furrr) # Used to do parallel processing with the topic models
plan(multiprocess)
# install.packages(&quot;quanteda&quot;)
library(quanteda) # Used for data cleaning
# install.packages(&quot;readtext&quot;)
library(readtext) # Used to read in the txt files that were scraped
# install.packages(&quot;stm&quot;)
library(stm) # Used for more interesting topic models
# install.packages(&quot;tictoc&quot;)
library(tictoc) # Used for timing
# install.packages(&quot;tidytext&quot;)
library(tidytext)
# install.packages(&quot;tidyverse&quot;)
library(tidyverse) # Used for everything
# install.packages(&#39;topicmodels&#39;)
library(topicmodels) # Used to make basic topic models

# Read in the text that we scraped earlier
text &lt;- readtext::readtext(&quot;inputs/minutes/*.txt&quot;) # readtext makes this easy, 
# but could also use the usual base approach of listing files that end in txt etc.</code></pre>
</div>
<p>In general you’ll often need to do a lot of cleaning before you can do the stats bit and get results. Here, I’ll just show two example steps. I’ve found that cleaning the dataset seems to take about 80 per cent of the time.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#### Clean data ####
# Do some basic cleaning - remove puncuation and change everything to lower case
text$text &lt;- str_to_lower(text$text)
text$text &lt;- str_replace_all(text$text, &quot;[:punct:]&quot;, &quot; &quot;)</code></pre>
</div>
<p>Now that we have a plausibly clean dataset (of course you’d want to come back and clean it more if you were actually interested in analysing the RBA minutes), we can try a topic model. Topic models are essentially just summaries. Instead of a document becoming a collection of words, they become a collection of topics with some probability associated with each topic.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#### First topic modelling ####
# Convert the corpus to a form that the topic model can work with
rba_minutes &lt;- quanteda::corpus(text) %&gt;% # Minimum viable conversion
  quanteda::dfm(remove_punct = TRUE, remove = stopwords(&#39;en&#39;)) %&gt;% # Get rid of
  # punctuation (in case you didn&#39;t already do that) and stop words - check 
  # those stop words assumptions
  quanteda::dfm_trim(min_termfreq = 2, # Remove any word that doesn&#39;t occur at 
                     # least twice
           min_docfreq = 2) # Get rid of any word that isn&#39;t in at least two documents

# Run the topic model with 10 topics
dtm &lt;- quanteda::convert(rba_minutes, to = &quot;topicmodels&quot;) # Getting the dfm 
# into a form that topicmodels can deal with
lda_topics &lt;- topicmodels::LDA(dtm, k = 10) # The k is the number of topics - 
# this decision has a big impact

# Have a look at the terms
terms(lda_topics, 10) # Top 10 words for each topic. Topics are just 
# probability distributions over words so you should look at different numbers of words</code></pre>
</div>
<p>Looking at the words in the topics, it seems as though “per” and “cent” are being treated as separate words. The RBA is proud that it separates “per” and “cent”, and if you’re a grad there that’ll stick with you for a while (see earlier paragraphs), but for our purposes they are one word and we need to combine them.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#### Clean data ####
# Let&#39;s deal with the first issue first.
text$text &lt;- stringr::str_replace_all(text$text, &quot;per cent&quot;, &quot;per_cent&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;per cent&quot;, &quot;per_cent&quot;)

# You could run the topic model again if you wanted.</code></pre>
</div>
<p>Right, that issue of per cent has been fixed, but what if there are combinations of words like this that don’t show up very high in the topics? To identify these we need to construct n-grams. Earlier with ‘per’ ‘cent’, we generated a 2-gram. Quanteda and the tidyverse makes it easy to identify popular n-grams (if your dataset is large then I’d work with a sample of it because these can get a little unwieldy, and we only really care about the popular ones anyway). Our text is in sentences, paragraphs, etc, and we first need to break it down into tokens (essentially separate words). There’s a wonderful set of tutorials put together by the quanteda team here: <a href="https://tutorials.quanteda.io" class="uri">https://tutorials.quanteda.io</a> and the code for this section is from: <a href="https://tutorials.quanteda.io/basic-operations/tokens/tokens_ngrams/" class="uri">https://tutorials.quanteda.io/basic-operations/tokens/tokens_ngrams/</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#### Adjusting for common co-location ####
toks &lt;- tokens(text$text)
# First generate 2-grams
ngrams &lt;- tokens_ngrams(toks, n = 2:4)
# Somewhat annoyingly for our purposes (although understandably given the broader 
# picture) quanteda puts tokens into its own class, so we need ot convert in 
# order to use the usual tidyverse tools that we may be more familiar with.
# As a side note, I often find it worthwhile to checking class in R when there&#39;s 
# an issue because often that&#39;s part of the issue, in this case: class(ngrams).
# The tokens class seems to just be a list, so we can unlist it and then put it 
# into a more-friendly tibble.
ngram_counts &lt;- tibble(ngrams = unlist(ngrams)) %&gt;% 
  count(ngrams, sort = TRUE)

# We can identify a bunch of obvious replacements. If we start getting a long 
# list then we can create a file that holds the replacement.
text$text &lt;- stringr::str_replace_all(text$text, &quot;assistant governor&quot;, &quot;assistant_governor&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;reserve bank board&quot;, &quot;reserve_bank_board&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;unemployment rate&quot;, &quot;unemployment_rate&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;national accounts&quot;, &quot;national_accounts&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;australian dollar&quot;, &quot;australian_dollar&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;monetary policy&quot;, &quot;monetary_policy&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;united states&quot;, &quot;united_states&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;exchange rate&quot;, &quot;exchange_rate&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;glenn stevens&quot;, &quot;glenn_stevens&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;reserve bank&quot;, &quot;reserve_bank&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;cash rate&quot;, &quot;cash_rate&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;us dollar&quot;, &quot;us_dollar&quot;)
text$text &lt;- stringr::str_replace_all(text$text, &quot;iron ore&quot;, &quot;iron_ore&quot;)

rm(toks, ngrams, ngram_counts)</code></pre>
</div>
<p>Take a look at the topics again. Notice that ‘growth’ is in essentially every topic. So is ‘members’ and a couple of others. It’s not that growth isn’t important (insert standard economist joke here), but the fact that ‘members’ shows up suggests that these may just be due to the way that language is used at the RBA, rather than communicating topics. If you read these minutes, you’ll know that the RBA starts a LOT of sentences with ‘Members noted…’. What does this mean for our purposes? Essentially, if you look at each topic by itself they seem ‘coherent’, but taken as a group it seems as though the topics are too similar. Another way to say that is that the words lack ‘exclusivity’. This is a common tradeoff, and our results suggest that it may be worthwhile for us to reduce some of the coherence in order to increase the exclusivity. At this point, we’ll use a different package for creating topic models - the STM package - because it has a bunch of nice features that you might like to take advantage of in future work.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#### Introducing STM and quanteda ####
rba_minutes &lt;- quanteda::corpus(text) %&gt;% # Minimum viable conversion
  quanteda::dfm(remove_punct = TRUE, 
                 remove_numbers = TRUE,
                 remove = stopwords(&#39;en&#39;)) %&gt;% # Get rid of punctuation (in 
  # case you didn&#39;t already do that) and stop words - check those stop words assumptions
  quanteda::dfm_trim(min_termfreq = 2, # Remove any word that doesn&#39;t occur at least twice
                     min_docfreq = 0.05, # Get rid of any word that isn&#39;t in at 
                     # least 5 per cent of documents
                     max_docfreq = 0.90, # Get rid of any word that is in at 
                     # least 90 per cent of documents
                     docfreq_type = &quot;prop&quot; # Above we specified percentages - you 
                     # could specify counts or ranks
                     ) 

# We can run the topic model using STM
topics_stm &lt;- stm(rba_minutes, K = 10)
# Looking at the results you can see that the results are fairly similar to 
# those that we got from the topicmodels package, which is what we want. 
labelTopics(topics_stm)
rm(topics_stm)
# If we were interested in the results then we might like to pre-process the text 
# a little more, for instance removing the names of months.</code></pre>
</div>
<p>Other than pre-processing decisions, the other major determininat of the outputs of topic models is the number of topics specified. There are a bunch of diagnostic tests that have been developed to help with this decision and we can use some nice code from Julia Silge (<a href="https://juliasilge.com/blog/evaluating-stm/" class="uri">https://juliasilge.com/blog/evaluating-stm/</a>) to try a bunch of different values for the number of topics.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#### Deciding on the number of topics ####
tic(&quot;With parallel&quot;) # This allows us to time the code
many_models &lt;- data_frame(K = seq(5, 20, by = 5)) %&gt;% # Here we&#39;re running four 
  # topic models: 5 topics, 10 topics, 15 topics and 20 topics
  mutate(topic_model = future_map(K, ~stm(rba_minutes, 
                                          K = .,
                                          verbose = FALSE)))
toc()

# You can also try setting K to zero within STM and seeing the number of topics 
# that it recommends: e,g, choose_topic_num_for_me &lt;- stm(rba_minutes, K = 0, verbose = FALSE)

# We want to compare those models with different numbers of topics using various diagnostics.
heldout &lt;- make.heldout(rba_minutes) # First create a test/training set

k_result &lt;- many_models %&gt;%
  mutate(exclusivity = map(topic_model, exclusivity), # How unique are words to the topics
         semantic_coherence = map(topic_model, semanticCoherence, rba_minutes), # How 
         # much the topics tend to be coherent if we look at them (usually a 
         # tradeoff with exclusivity)
         eval_heldout = map(topic_model, eval.heldout, heldout$missing),
         residual = map(topic_model, checkResiduals, rba_minutes),
         bound =  map_dbl(topic_model, function(x) max(x$convergence$bound)),
         lfact = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
         lbound = bound + lfact,
         iterations = map_dbl(topic_model, function(x) length(x$convergence$bound)))</code></pre>
</div>
<p>Put these diagnostics into a nice summary graph (again code is Julia’s originally).</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
k_result %&gt;%
  transmute(K,
            `Lower bound` = lbound,
            Residuals = map_dbl(residual, &quot;dispersion&quot;),
            `Semantic coherence` = map_dbl(semantic_coherence, mean),
            `Held-out likelihood` = map_dbl(eval_heldout, &quot;expected.heldout&quot;)) %&gt;%
  gather(Metric, Value, -K) %&gt;%
  ggplot(aes(K, Value, color = Metric)) +
  geom_line(show.legend = FALSE) +
  facet_wrap(~Metric, scales = &quot;free_y&quot;) +
  labs(x = &quot;K (number of topics)&quot;,
       y = NULL,
       title = &quot;Model diagnostics by number of topics&quot;) +
  theme_minimal()</code></pre>
<p><img src="gathering-and-analysing-text-data_files/figure-html5/diagnosticmeasuregraphs-1.png" width="624" /></p>
</div>
<p>In general we are looking for the max/min of parabolas, so our results suggest we may be best with some more topics (go to Julia’s post for to see another example: <a href="https://juliasilge.com/blog/evaluating-stm/" class="uri">https://juliasilge.com/blog/evaluating-stm/</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# Have a look at that exclusivity to coherence tradeoff
k_result %&gt;%
  select(K, exclusivity, semantic_coherence) %&gt;%
  unnest() %&gt;%
  mutate(K = as.factor(K)) %&gt;%
  ggplot(aes(semantic_coherence, exclusivity)) +
  geom_point() +
  facet_wrap(vars(K)) +
  labs(x = &quot;Semantic coherence&quot;,
       y = &quot;Exclusivity&quot;,
       title = &quot;Comparing exclusivity and semantic coherence&quot;) +
  theme_minimal()</code></pre>
<p><img src="gathering-and-analysing-text-data_files/figure-html5/exlusitivty-1.png" width="624" /></p>
</div>
<p>Although you’d probably want more, let’s just choose 10 topics for now. What we’re most interested in is getting the betas and gammas so that we can do our usual analysis.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
topic_model &lt;- k_result %&gt;% 
  filter(K == 10) %&gt;% 
  pull(topic_model) %&gt;% 
  .[[1]]

# Grab the betas - these are the probability of each term in each topic
td_beta &lt;- broom::tidy(topic_model, 
                       matrix = &quot;beta&quot;)

# Grab the gammas - these are the probability of each word in each topic
td_gamma &lt;- tidy(topic_model, 
                 matrix = &quot;gamma&quot;,
                 document_names = rownames(rba_minutes))</code></pre>
</div>
<p>From here you could look at how the gammas and betas evolve or change using a statistical model. Or even sometimes just looking at them is interesting. Julia Silge has a bunch of code that makes very nice graphs and tables. One of the advantages of the STM package is that it makes it easier to include specific types of additional information. For instance, we know that over our time period there have been two governors: GRS and Phil Lowe. We could associate each date with who the governor is and then allow that to affect the prevalence of certain topics.</p>
<p>You can grab the files and folder set up from GitHub if you’d like.</p>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
